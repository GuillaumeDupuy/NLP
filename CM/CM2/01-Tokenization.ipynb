{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "La première étape de la création d'un objet `Doc` consiste à décomposer le texte entrant en éléments constitutifs ou \"tokens\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spaCy and load the language library\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"We're moving to L.A.!\"\n"
     ]
    }
   ],
   "source": [
    "# Create a string that includes opening and closing quotation marks\n",
    "mystring = '\"We\\'re moving to L.A.!\"'\n",
    "print(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" | We | 're | moving | to | L.A. | ! | \" | "
     ]
    }
   ],
   "source": [
    "# Create a Doc object and explore tokens\n",
    "doc = nlp(mystring)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, end=' | ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  **Prefix**:\tCharacter(s) at the beginning &#9656; `$ ( “ ¿`\n",
    "-  **Suffix**:\tCharacter(s) at the end &#9656; `km ) , . ! ”`\n",
    "-  **Infix**:\tCharacter(s) in between &#9656; `- -- / ...`\n",
    "-  **Exception**: Special-case rule to split a string into several tokens or prevent a token from being split when punctuation rules are applied &#9656; `St. U.S.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../tokenization.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notez que les tokens sont des morceaux du texte original. En d'autres termes, nous ne voyons pas de conversion en stems de mots ou en lemmas (formes de base des mots) et nous n'avons rien vu sur les organisations/lieux/monnaies, etc. Les tokens sont les éléments de base d'un objet Doc - tout ce qui nous aide à comprendre le sens du texte est dérivé des tokens et de leur relation les uns avec les autres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préfixes, suffixes et infixes\n",
    "spaCy isolera la ponctuation qui ne fait pas partie intégrante d'un mot. Les guillemets, les virgules et la ponctuation en fin de phrase se verront attribuer leur propre token. Toutefois, la ponctuation qui fait partie d'une adresse électronique, d'un site web ou d'une valeur numérique sera conservée comme partie intégrante du token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "'re\n",
      "here\n",
      "to\n",
      "help\n",
      "!\n",
      "Send\n",
      "snail\n",
      "-\n",
      "mail\n",
      ",\n",
      "email\n",
      "support@oursite.com\n",
      "or\n",
      "visit\n",
      "us\n",
      "at\n",
      "http://www.oursite.com\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u\"We're here to help! Send snail-mail, email support@oursite.com or visit us at http://www.oursite.com!\")\n",
    "\n",
    "for t in doc2:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>Notez que les points d'exclamation, la virgule et le trait d'union dans \"snail-mail\" se voient attribuer leurs propres tokens, mais que l'adresse électronique et le site web sont conservés..</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "5\n",
      "km\n",
      "NYC\n",
      "cab\n",
      "ride\n",
      "costs\n",
      "$\n",
      "10.30\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp(u'A 5km NYC cab ride costs $10.30')\n",
    "\n",
    "for t in doc3:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>Ici, l'unité de distance et le signe du dollar se voient attribuer leurs propres token, mais le montant en dollars est conservé.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptions\n",
    "La ponctuation qui fait partie d'une abréviation connue sera conservée en tant que partie du token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let\n",
      "'s\n",
      "visit\n",
      "St.\n",
      "Louis\n",
      "in\n",
      "the\n",
      "U.S.\n",
      "next\n",
      "year\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp(u\"Let's visit St. Louis in the U.S. next year.\")\n",
    "\n",
    "for t in doc4:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>Ici, les abréviations pour \"Saint\" et \"United States\" sont toutes deux conservées.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compter les tokens\n",
    "Les objets `Doc` ont un nombre défini de tokens :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compter les entrées du Vocabulaire\n",
    "Les objets `Vocab` contiennent une bibliothèque complète d'éléments !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57852"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"\"',\n",
       " '#',\n",
       " '$',\n",
       " \"''\",\n",
       " ',',\n",
       " '-LRB-',\n",
       " '-RRB-',\n",
       " '.',\n",
       " ':',\n",
       " 'ADD',\n",
       " 'AFX',\n",
       " 'BES',\n",
       " 'CC',\n",
       " 'CD',\n",
       " 'DT',\n",
       " 'EX',\n",
       " 'FW',\n",
       " 'GW',\n",
       " 'HVS',\n",
       " 'HYPH',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'JJR',\n",
       " 'JJS',\n",
       " 'LS',\n",
       " 'MD',\n",
       " 'NFP',\n",
       " 'NIL',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'NNPS',\n",
       " 'NNS',\n",
       " 'PDT',\n",
       " 'PRP',\n",
       " 'PRP$',\n",
       " 'RB',\n",
       " 'RBR',\n",
       " 'RBS',\n",
       " 'RP',\n",
       " 'SP',\n",
       " 'TO',\n",
       " 'UH',\n",
       " 'VB',\n",
       " 'VBD',\n",
       " 'VBG',\n",
       " 'VBN',\n",
       " 'VBP',\n",
       " 'VBZ',\n",
       " 'WDT',\n",
       " 'WP',\n",
       " 'WP$',\n",
       " 'WRB',\n",
       " 'XX',\n",
       " '_SP',\n",
       " '``',\n",
       " '-PRON-',\n",
       " 'be',\n",
       " '\\t',\n",
       " 'en',\n",
       " '\\n',\n",
       " ' ',\n",
       " '\")',\n",
       " '\"',\n",
       " \"'\",\n",
       " \"'Cause\",\n",
       " 'because',\n",
       " \"'cause\",\n",
       " 'use',\n",
       " \"'Xxxxx\",\n",
       " \"'Cos\",\n",
       " \"'cos\",\n",
       " 'Cos',\n",
       " \"'Xxx\",\n",
       " \"'Coz\",\n",
       " \"'coz\",\n",
       " 'Coz',\n",
       " \"'Cuz\",\n",
       " \"'cuz\",\n",
       " 'Cuz',\n",
       " \"'S\",\n",
       " \"'s\",\n",
       " \"'X\",\n",
       " \"'bout\",\n",
       " 'about',\n",
       " 'out',\n",
       " \"'xxxx\",\n",
       " 'cos',\n",
       " \"'xxx\",\n",
       " 'coz',\n",
       " 'cuz',\n",
       " \"'d\",\n",
       " \"'x\",\n",
       " \"'em\",\n",
       " 'them',\n",
       " \"'xx\",\n",
       " \"'ll\",\n",
       " 'will',\n",
       " \"'nuff\",\n",
       " 'enough',\n",
       " 'uff',\n",
       " \"'re\",\n",
       " 'are',\n",
       " '(*_*)',\n",
       " '(',\n",
       " '_*)',\n",
       " '(-8',\n",
       " '(-d',\n",
       " '(-:',\n",
       " '(-;',\n",
       " '(-_-)',\n",
       " '_-)',\n",
       " '(._.)',\n",
       " '_.)',\n",
       " '(:',\n",
       " '(;',\n",
       " '(=',\n",
       " '(>_<)',\n",
       " '_<)',\n",
       " '(^_^)',\n",
       " '_^)',\n",
       " '(o:',\n",
       " '(x:',\n",
       " '(¬_¬)',\n",
       " '_¬)',\n",
       " '(ಠ_ಠ)',\n",
       " '_ಠ)',\n",
       " '(x_x)',\n",
       " '(╯°□°）╯︵┻━┻',\n",
       " '┻━┻',\n",
       " ')-:',\n",
       " ')',\n",
       " '):',\n",
       " '-_-',\n",
       " '-',\n",
       " '-__-',\n",
       " '__-',\n",
       " '._.',\n",
       " '0.0',\n",
       " '0',\n",
       " 'd.d',\n",
       " '0.o',\n",
       " 'd.x',\n",
       " '0_0',\n",
       " 'd_d',\n",
       " '0_o',\n",
       " 'd_x',\n",
       " '10',\n",
       " '1',\n",
       " 'dd',\n",
       " 'a.m.',\n",
       " 'a',\n",
       " '.m.',\n",
       " 'x.x.',\n",
       " 'am',\n",
       " 'xx',\n",
       " 'p.m.',\n",
       " 'p',\n",
       " 'pm',\n",
       " '11',\n",
       " '12',\n",
       " 'd',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8)',\n",
       " '8',\n",
       " 'd)',\n",
       " '8-)',\n",
       " 'd-)',\n",
       " '8-D',\n",
       " '8-d',\n",
       " 'd-X',\n",
       " '8D',\n",
       " '8d',\n",
       " 'dX',\n",
       " '9',\n",
       " \":'(\",\n",
       " \":')\",\n",
       " \":'-(\",\n",
       " \"'-(\",\n",
       " \":'-)\",\n",
       " \"'-)\",\n",
       " ':(',\n",
       " ':((',\n",
       " ':(((',\n",
       " '(((',\n",
       " ':()',\n",
       " ':)',\n",
       " ':))',\n",
       " ':)))',\n",
       " ')))',\n",
       " ':*',\n",
       " ':-(',\n",
       " ':-((',\n",
       " '-((',\n",
       " ':-(((',\n",
       " ':-)',\n",
       " ':-))',\n",
       " '-))',\n",
       " ':-)))',\n",
       " ':-*',\n",
       " ':-/',\n",
       " ':-0',\n",
       " ':-d',\n",
       " ':-3',\n",
       " ':->',\n",
       " ':-D',\n",
       " ':-X',\n",
       " ':-O',\n",
       " ':-o',\n",
       " ':-P',\n",
       " ':-p',\n",
       " ':-x',\n",
       " ':-]',\n",
       " ':-|',\n",
       " ':-}',\n",
       " ':/',\n",
       " ':0',\n",
       " ':d',\n",
       " ':1',\n",
       " ':3',\n",
       " ':>',\n",
       " ':D',\n",
       " ':X',\n",
       " ':O',\n",
       " ':o',\n",
       " ':P',\n",
       " ':p',\n",
       " ':x',\n",
       " ':]',\n",
       " ':o)',\n",
       " ':x)',\n",
       " ':|',\n",
       " ':}',\n",
       " ':’(',\n",
       " ':’)',\n",
       " ':’-(',\n",
       " '’-(',\n",
       " ':’-)',\n",
       " '’-)',\n",
       " ';)',\n",
       " ';',\n",
       " ';-)',\n",
       " ';-D',\n",
       " ';-d',\n",
       " ';-X',\n",
       " ';D',\n",
       " ';d',\n",
       " ';X',\n",
       " ';_;',\n",
       " '<.<',\n",
       " '<',\n",
       " '</3',\n",
       " '</d',\n",
       " '<3',\n",
       " '<d',\n",
       " '<33',\n",
       " '<dd',\n",
       " '<333',\n",
       " '333',\n",
       " '<ddd',\n",
       " '<space>',\n",
       " 'ce>',\n",
       " '<xxxx>',\n",
       " '=(',\n",
       " '=',\n",
       " '=)',\n",
       " '=/',\n",
       " '=3',\n",
       " '=d',\n",
       " '=D',\n",
       " '=X',\n",
       " '=|',\n",
       " '>.<',\n",
       " '>',\n",
       " '>.>',\n",
       " '>:(',\n",
       " '>:o',\n",
       " '>:x',\n",
       " '><(((*>',\n",
       " '(*>',\n",
       " '@_@',\n",
       " '@',\n",
       " 'Adm.',\n",
       " 'adm.',\n",
       " 'A',\n",
       " 'dm.',\n",
       " 'Xxx.',\n",
       " 'Ai',\n",
       " 'ai',\n",
       " 'Xx',\n",
       " \"n't\",\n",
       " 'not',\n",
       " 'n',\n",
       " \"x'x\",\n",
       " 'nt',\n",
       " 'n’t',\n",
       " 'x’x',\n",
       " 'Ak.',\n",
       " 'Alaska',\n",
       " 'ak.',\n",
       " 'Xx.',\n",
       " 'Ala.',\n",
       " 'Alabama',\n",
       " 'ala.',\n",
       " 'la.',\n",
       " 'Apr.',\n",
       " 'April',\n",
       " 'apr.',\n",
       " 'pr.',\n",
       " 'Are',\n",
       " 'Xxx',\n",
       " 'Ariz.',\n",
       " 'Arizona',\n",
       " 'ariz.',\n",
       " 'iz.',\n",
       " 'Xxxx.',\n",
       " 'Ark.',\n",
       " 'Arkansas',\n",
       " 'ark.',\n",
       " 'rk.',\n",
       " 'Aug.',\n",
       " 'August',\n",
       " 'aug.',\n",
       " 'ug.',\n",
       " 'Bros.',\n",
       " 'bros.',\n",
       " 'B',\n",
       " 'os.',\n",
       " 'C++',\n",
       " 'c++',\n",
       " 'C',\n",
       " 'X++',\n",
       " 'Calif.',\n",
       " 'California',\n",
       " 'calif.',\n",
       " 'if.',\n",
       " 'Xxxxx.',\n",
       " 'Ca',\n",
       " 'can',\n",
       " 'ca',\n",
       " \"'ve\",\n",
       " 'have',\n",
       " 'Can',\n",
       " 'xxx',\n",
       " 've',\n",
       " 'v',\n",
       " '’ve',\n",
       " '’',\n",
       " '’xx',\n",
       " 'Co.',\n",
       " 'co.',\n",
       " 'Colo.',\n",
       " 'Colorado',\n",
       " 'colo.',\n",
       " 'lo.',\n",
       " 'Conn.',\n",
       " 'Connecticut',\n",
       " 'conn.',\n",
       " 'nn.',\n",
       " 'Corp.',\n",
       " 'corp.',\n",
       " 'rp.',\n",
       " 'Could',\n",
       " 'could',\n",
       " 'uld',\n",
       " 'Xxxxx',\n",
       " 'D.C.',\n",
       " 'd.c.',\n",
       " 'D',\n",
       " '.C.',\n",
       " 'X.X.',\n",
       " 'Dare',\n",
       " 'dare',\n",
       " 'Xxxx',\n",
       " 'Dec.',\n",
       " 'December',\n",
       " 'dec.',\n",
       " 'ec.',\n",
       " 'Del.',\n",
       " 'Delaware',\n",
       " 'del.',\n",
       " 'el.',\n",
       " 'Did',\n",
       " 'do',\n",
       " 'did',\n",
       " 'Does',\n",
       " 'does',\n",
       " 'oes',\n",
       " 'Doin',\n",
       " 'doing',\n",
       " 'doin',\n",
       " 'oin',\n",
       " \"Doin'\",\n",
       " \"doin'\",\n",
       " \"in'\",\n",
       " \"Xxxx'\",\n",
       " 'Doin’',\n",
       " 'doin’',\n",
       " 'in’',\n",
       " 'Xxxx’',\n",
       " 'Do',\n",
       " 'Dr.',\n",
       " 'dr.',\n",
       " 'E.G.',\n",
       " 'e.g.',\n",
       " 'E',\n",
       " '.G.',\n",
       " 'E.g.',\n",
       " '.g.',\n",
       " 'X.x.',\n",
       " 'Feb.',\n",
       " 'February',\n",
       " 'feb.',\n",
       " 'F',\n",
       " 'eb.',\n",
       " 'Fla.',\n",
       " 'Florida',\n",
       " 'fla.',\n",
       " 'Ga.',\n",
       " 'Georgia',\n",
       " 'ga.',\n",
       " 'G',\n",
       " 'Gen.',\n",
       " 'gen.',\n",
       " 'en.',\n",
       " 'Goin',\n",
       " 'go',\n",
       " 'going',\n",
       " 'goin',\n",
       " \"Goin'\",\n",
       " \"goin'\",\n",
       " 'Goin’',\n",
       " 'goin’',\n",
       " 'Gon',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'to',\n",
       " 'Got',\n",
       " 'got',\n",
       " 'ta',\n",
       " 't',\n",
       " 'Gov.',\n",
       " 'gov.',\n",
       " 'ov.',\n",
       " 'Had',\n",
       " 'had',\n",
       " 'H',\n",
       " 'Has',\n",
       " 'has',\n",
       " 'Have',\n",
       " 'ave',\n",
       " 'He',\n",
       " 'he',\n",
       " 'would',\n",
       " 'x',\n",
       " 'll',\n",
       " 'l',\n",
       " 's',\n",
       " '’d',\n",
       " '’x',\n",
       " '’ll',\n",
       " '’s',\n",
       " 'How',\n",
       " 'how',\n",
       " \"'y\",\n",
       " 'you',\n",
       " 're',\n",
       " 'r',\n",
       " '’y',\n",
       " '’re',\n",
       " 'I',\n",
       " 'i',\n",
       " \"'m\",\n",
       " 'going to',\n",
       " 'gonna',\n",
       " 'I.E.',\n",
       " 'i.e.',\n",
       " '.E.',\n",
       " 'I.e.',\n",
       " '.e.',\n",
       " 'Ia.',\n",
       " 'Iowa',\n",
       " 'ia.',\n",
       " 'Id.',\n",
       " 'Idaho',\n",
       " 'id.',\n",
       " 'Ill.',\n",
       " 'Illinois',\n",
       " 'ill.',\n",
       " 'll.',\n",
       " 'm',\n",
       " 'Inc.',\n",
       " 'inc.',\n",
       " 'nc.',\n",
       " 'Ind.',\n",
       " 'Indiana',\n",
       " 'ind.',\n",
       " 'nd.',\n",
       " 'Is',\n",
       " 'is',\n",
       " 'It',\n",
       " 'it',\n",
       " '’m',\n",
       " 'Jan.',\n",
       " 'January',\n",
       " 'jan.',\n",
       " 'J',\n",
       " 'an.',\n",
       " 'Jr.',\n",
       " 'jr.',\n",
       " 'Jul.',\n",
       " 'July',\n",
       " 'jul.',\n",
       " 'ul.',\n",
       " 'Jun.',\n",
       " 'June',\n",
       " 'jun.',\n",
       " 'un.',\n",
       " 'Kan.',\n",
       " 'Kansas',\n",
       " 'kan.',\n",
       " 'K',\n",
       " 'Kans.',\n",
       " 'kans.',\n",
       " 'ns.',\n",
       " 'Ky.',\n",
       " 'Kentucky',\n",
       " 'ky.',\n",
       " 'La.',\n",
       " 'Louisiana',\n",
       " 'L',\n",
       " 'Let',\n",
       " 'let',\n",
       " 'us',\n",
       " 'Ltd.',\n",
       " 'ltd.',\n",
       " 'td.',\n",
       " \"Ma'am\",\n",
       " 'madam',\n",
       " \"ma'am\",\n",
       " 'M',\n",
       " \"'am\",\n",
       " \"Xx'xx\",\n",
       " 'Mar.',\n",
       " 'March',\n",
       " 'mar.',\n",
       " 'ar.',\n",
       " 'Mass.',\n",
       " 'Massachusetts',\n",
       " 'mass.',\n",
       " 'ss.',\n",
       " 'May.',\n",
       " 'May',\n",
       " 'may.',\n",
       " 'ay.',\n",
       " 'may',\n",
       " 'Ma’am',\n",
       " 'ma’am',\n",
       " '’am',\n",
       " 'Xx’xx',\n",
       " 'Md.',\n",
       " 'md.',\n",
       " 'Messrs.',\n",
       " 'messrs.',\n",
       " 'rs.',\n",
       " 'Mich.',\n",
       " 'Michigan',\n",
       " 'mich.',\n",
       " 'ch.',\n",
       " 'Might',\n",
       " 'might',\n",
       " 'ght',\n",
       " 'Minn.',\n",
       " 'Minnesota',\n",
       " 'minn.',\n",
       " 'Miss.',\n",
       " 'Mississippi',\n",
       " 'miss.',\n",
       " 'Mo.',\n",
       " 'mo.',\n",
       " 'Mont.',\n",
       " 'mont.',\n",
       " 'nt.',\n",
       " 'Mr.',\n",
       " 'mr.',\n",
       " 'Mrs.',\n",
       " 'mrs.',\n",
       " 'Ms.',\n",
       " 'ms.',\n",
       " 'Mt.',\n",
       " 'Mount',\n",
       " 'mt.',\n",
       " 'Must',\n",
       " 'must',\n",
       " 'ust',\n",
       " 'N.C.',\n",
       " 'North Carolina',\n",
       " 'n.c.',\n",
       " 'N',\n",
       " 'N.D.',\n",
       " 'North Dakota',\n",
       " 'n.d.',\n",
       " '.D.',\n",
       " 'N.H.',\n",
       " 'New Hampshire',\n",
       " 'n.h.',\n",
       " '.H.',\n",
       " 'N.J.',\n",
       " 'New Jersey',\n",
       " 'n.j.',\n",
       " '.J.',\n",
       " 'N.M.',\n",
       " 'New Mexico',\n",
       " 'n.m.',\n",
       " '.M.',\n",
       " 'N.Y.',\n",
       " 'New York',\n",
       " 'n.y.',\n",
       " '.Y.',\n",
       " 'Neb.',\n",
       " 'Nebraska',\n",
       " 'neb.',\n",
       " 'Nebr.',\n",
       " 'nebr.',\n",
       " 'br.',\n",
       " 'Need',\n",
       " 'need',\n",
       " 'eed',\n",
       " 'Nev.',\n",
       " 'Nevada',\n",
       " 'nev.',\n",
       " 'ev.',\n",
       " 'Not',\n",
       " 'Nothin',\n",
       " 'nothing',\n",
       " 'nothin',\n",
       " 'hin',\n",
       " \"Nothin'\",\n",
       " \"nothin'\",\n",
       " \"Xxxxx'\",\n",
       " 'Nothin’',\n",
       " 'nothin’',\n",
       " 'Xxxxx’',\n",
       " 'Nov.',\n",
       " 'November',\n",
       " 'nov.',\n",
       " 'Nuthin',\n",
       " 'nuthin',\n",
       " \"Nuthin'\",\n",
       " \"nuthin'\",\n",
       " 'Nuthin’',\n",
       " 'nuthin’',\n",
       " \"O'clock\",\n",
       " \"o'clock\",\n",
       " 'O',\n",
       " 'ock',\n",
       " \"X'xxxx\",\n",
       " 'O.O',\n",
       " 'o.o',\n",
       " 'X.X',\n",
       " 'O.o',\n",
       " 'X.x',\n",
       " 'O_O',\n",
       " 'o_o',\n",
       " 'X_X',\n",
       " 'O_o',\n",
       " 'X_x',\n",
       " 'Oct.',\n",
       " 'October',\n",
       " 'oct.',\n",
       " 'ct.',\n",
       " 'Okla.',\n",
       " 'Oklahoma',\n",
       " 'okla.',\n",
       " 'Ol',\n",
       " 'old',\n",
       " 'ol',\n",
       " \"Ol'\",\n",
       " \"ol'\",\n",
       " \"Xx'\",\n",
       " 'Ol’',\n",
       " 'ol’',\n",
       " 'Xx’',\n",
       " 'Ore.',\n",
       " 'Oregon',\n",
       " 'ore.',\n",
       " 're.',\n",
       " 'Ought',\n",
       " 'ought',\n",
       " 'O’clock',\n",
       " 'o’clock',\n",
       " 'X’xxxx',\n",
       " 'Pa.',\n",
       " 'Pennsylvania',\n",
       " 'pa.',\n",
       " 'P',\n",
       " 'Ph.D.',\n",
       " 'ph.d.',\n",
       " 'Xx.X.',\n",
       " 'Rep.',\n",
       " 'rep.',\n",
       " 'R',\n",
       " 'ep.',\n",
       " 'Rev.',\n",
       " 'rev.',\n",
       " 'S.C.',\n",
       " 'South Carolina',\n",
       " 's.c.',\n",
       " 'S',\n",
       " 'Sen.',\n",
       " 'sen.',\n",
       " 'Sep.',\n",
       " 'September',\n",
       " 'sep.',\n",
       " 'Sept.',\n",
       " 'sept.',\n",
       " 'pt.',\n",
       " 'Sha',\n",
       " 'shall',\n",
       " 'sha',\n",
       " 'She',\n",
       " 'she',\n",
       " 'Should',\n",
       " 'should',\n",
       " 'Somethin',\n",
       " 'something',\n",
       " 'somethin',\n",
       " \"Somethin'\",\n",
       " \"somethin'\",\n",
       " 'Somethin’',\n",
       " 'somethin’',\n",
       " 'St.',\n",
       " 'st.',\n",
       " 'Tenn.',\n",
       " 'Tennessee',\n",
       " 'tenn.',\n",
       " 'T',\n",
       " 'That',\n",
       " 'that',\n",
       " 'hat',\n",
       " 'There',\n",
       " 'there',\n",
       " 'ere',\n",
       " 'They',\n",
       " 'they',\n",
       " 'hey',\n",
       " 'V.V',\n",
       " 'v.v',\n",
       " 'V',\n",
       " 'V_V',\n",
       " 'v_v',\n",
       " 'Va.',\n",
       " 'Virginia',\n",
       " 'va.',\n",
       " 'Wash.',\n",
       " 'Washington',\n",
       " 'wash.',\n",
       " 'W',\n",
       " 'sh.',\n",
       " 'Was',\n",
       " 'was',\n",
       " 'We',\n",
       " 'we',\n",
       " 'Were',\n",
       " 'were',\n",
       " 'What',\n",
       " 'what',\n",
       " 'When',\n",
       " 'when',\n",
       " 'hen',\n",
       " 'Where',\n",
       " 'where',\n",
       " 'Who',\n",
       " 'who',\n",
       " 'Why',\n",
       " 'why',\n",
       " 'Wis.',\n",
       " 'Wisconsin',\n",
       " 'wis.',\n",
       " 'is.',\n",
       " 'Wo',\n",
       " 'wo',\n",
       " 'Would',\n",
       " 'XD',\n",
       " 'xd',\n",
       " 'XDD',\n",
       " 'xdd',\n",
       " 'XXX',\n",
       " 'You',\n",
       " 'Y',\n",
       " '[-:',\n",
       " '[',\n",
       " '[:',\n",
       " '\\\\\")',\n",
       " '\\\\',\n",
       " '\\\\n',\n",
       " '\\\\x',\n",
       " '\\\\t',\n",
       " '^_^',\n",
       " '^',\n",
       " '^__^',\n",
       " '__^',\n",
       " '^___^',\n",
       " 'a.',\n",
       " 'x.',\n",
       " 'and/or',\n",
       " '/or',\n",
       " 'xxx/xx',\n",
       " 'b.',\n",
       " 'b',\n",
       " 'c.',\n",
       " 'c',\n",
       " 'cause',\n",
       " 'xxxx',\n",
       " 'xx.',\n",
       " 'd.',\n",
       " \"xxxx'\",\n",
       " 'xxxx’',\n",
       " 'e.',\n",
       " 'e',\n",
       " 'em',\n",
       " 'f.',\n",
       " 'f',\n",
       " 'g.',\n",
       " 'g',\n",
       " 'h.',\n",
       " 'h',\n",
       " 'i.',\n",
       " 'j.',\n",
       " 'j',\n",
       " 'k.',\n",
       " 'k',\n",
       " 'l.',\n",
       " 'm.',\n",
       " \"xx'xx\",\n",
       " 'xx’xx',\n",
       " 'n.',\n",
       " 'nuff',\n",
       " 'o',\n",
       " \"x'xxxx\",\n",
       " 'o.',\n",
       " 'o.0',\n",
       " 'x.d',\n",
       " 'o.O',\n",
       " 'x.X',\n",
       " 'x.x',\n",
       " 'o_0',\n",
       " 'x_d',\n",
       " 'o_O',\n",
       " 'x_X',\n",
       " 'x_x',\n",
       " \"xx'\",\n",
       " 'xx’',\n",
       " 'x’xxxx',\n",
       " 'p.',\n",
       " 'q.',\n",
       " 'q',\n",
       " 'r.',\n",
       " 's.',\n",
       " 't.',\n",
       " 'u.',\n",
       " 'u',\n",
       " 'v.',\n",
       " 'vs.',\n",
       " 'w.',\n",
       " 'w',\n",
       " 'w/o',\n",
       " 'without',\n",
       " 'x/x',\n",
       " 'xD',\n",
       " 'xX',\n",
       " 'xDD',\n",
       " 'xXX',\n",
       " \"y'\",\n",
       " 'y',\n",
       " \"x'\",\n",
       " 'all',\n",
       " 'y.',\n",
       " 'y’',\n",
       " 'x’',\n",
       " 'z.',\n",
       " 'z',\n",
       " '\\xa0',\n",
       " '  ',\n",
       " '¯\\\\(ツ)/¯',\n",
       " '¯',\n",
       " ')/¯',\n",
       " '¯\\\\(x)/¯',\n",
       " 'ä.',\n",
       " 'ä',\n",
       " 'ö.',\n",
       " 'ö',\n",
       " 'ü.',\n",
       " 'ü',\n",
       " 'ಠ_ಠ',\n",
       " 'ಠ',\n",
       " 'ಠ︵ಠ',\n",
       " 'x︵x',\n",
       " '—',\n",
       " '--',\n",
       " '‘S',\n",
       " '‘s',\n",
       " '‘',\n",
       " '‘X',\n",
       " '‘x',\n",
       " '’Cause',\n",
       " '’cause',\n",
       " '’Xxxxx',\n",
       " '’Cos',\n",
       " '’cos',\n",
       " '’Xxx',\n",
       " '’Coz',\n",
       " '’coz',\n",
       " '’Cuz',\n",
       " '’cuz',\n",
       " '’S',\n",
       " '’X',\n",
       " '’bout',\n",
       " '’xxxx',\n",
       " '’xxx',\n",
       " '’em',\n",
       " '’nuff',\n",
       " '’’',\n",
       " 'ROOT',\n",
       " 'This',\n",
       " 'this',\n",
       " 'his',\n",
       " 'the',\n",
       " 'family',\n",
       " 'ily',\n",
       " 'history',\n",
       " 'ory',\n",
       " 'of',\n",
       " 'Jesus',\n",
       " 'jesus',\n",
       " 'sus',\n",
       " 'Christ',\n",
       " 'christ',\n",
       " 'ist',\n",
       " 'came',\n",
       " 'ame',\n",
       " 'from',\n",
       " 'rom',\n",
       " 'David',\n",
       " 'david',\n",
       " 'vid',\n",
       " 'and',\n",
       " 'Abraham',\n",
       " 'abraham',\n",
       " 'ham',\n",
       " 'father',\n",
       " 'her',\n",
       " 'Isaac',\n",
       " 'isaac',\n",
       " 'aac',\n",
       " 'Jacob',\n",
       " 'jacob',\n",
       " 'cob',\n",
       " 'Judah',\n",
       " 'judah',\n",
       " 'dah',\n",
       " 'brothers',\n",
       " 'ers',\n",
       " 'Perez',\n",
       " 'perez',\n",
       " 'rez',\n",
       " 'Zerah',\n",
       " 'zerah',\n",
       " 'Z',\n",
       " 'rah',\n",
       " 'Their',\n",
       " 'their',\n",
       " 'eir',\n",
       " 'mother',\n",
       " 'Tamar',\n",
       " 'tamar',\n",
       " 'mar',\n",
       " 'Hezron',\n",
       " 'hezron',\n",
       " 'ron',\n",
       " 'Ram',\n",
       " 'ram',\n",
       " 'Amminadab',\n",
       " 'amminadab',\n",
       " 'dab',\n",
       " 'Nahshon',\n",
       " 'nahshon',\n",
       " 'hon',\n",
       " 'Salmon',\n",
       " 'salmon',\n",
       " 'mon',\n",
       " 'Boaz',\n",
       " 'boaz',\n",
       " 'oaz',\n",
       " 'His',\n",
       " 'Rahab',\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc.vocab.strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>NOTE : Ce nombre change en fonction de la bibliothèque de langue chargée au départ, et de tout nouveau lexème introduit dans le `vocab` lors de la création du `Doc`.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les tokens peuvent être récupérés par position d'index et par slice.\n",
    "Les objets `Doc` peuvent être considérés comme des listes d'objets `token`. En tant que tels, les tokens individuels peuvent être récupérés par la position de l'index, et les étendues de tokens peuvent être récupérées par le découpage en tranches :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "better"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc5 = nlp(u'It is better to give than to receive.')\n",
    "\n",
    "# Retrieve the third token:\n",
    "doc5[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "better to give"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve three tokens from the middle:\n",
    "doc5[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "than to receive."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the last four tokens:\n",
    "doc5[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les tokens ne peuvent pas être réaffectés\n",
    "Bien que les objets `Doc` puissent être considérés comme des listes de tokens, ils ne supportent pas la réaffectation d'éléments :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc6 = nlp(u'My dinner was horrible.')\n",
    "doc7 = nlp(u'Your dinner was delicious.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'spacy.tokens.doc.Doc' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21012\\2197368727.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Try to change \"My dinner was horrible\" to \"My dinner was delicious\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdoc6\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc7\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'spacy.tokens.doc.Doc' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# Try to change \"My dinner was horrible\" to \"My dinner was delicious\"\n",
    "doc6[3] = doc7[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Entités nommées ou Named Entities\n",
    "Au-delà des tokens, les *entités nommées* ajoutent une autre couche de contexte. Le modèle de langage reconnaît que certains mots sont des noms d'organisations, d'autres des lieux, et d'autres combinaisons encore se rapportent à l'argent, aux dates, etc. Les entités nommées sont accessibles via la propriété `ents` d'un objet `Doc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple | to | build | a | Hong | Kong | factory | for | $ | 6 | million | \n",
      "----\n",
      "Apple - ORG - Companies, agencies, institutions, etc.\n",
      "Hong Kong - GPE - Countries, cities, states\n",
      "$6 million - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc8 = nlp(u'Apple to build a Hong Kong factory for $6 million')\n",
    "\n",
    "for token in doc8:\n",
    "    print(token.text, end=' | ')\n",
    "\n",
    "print('\\n----')\n",
    "\n",
    "for ent in doc8.ents:\n",
    "    print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>Notez que deux jetons se combinent pour former l'entité `Hong Kong`, et que trois tokens se combinent pour former l'entité monétaire : `$6 million`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc8.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La reconnaissance des entités nommées (NER) est un outil important d'apprentissage automatique appliqué au traitement du langage naturel. Pour plus d'informations sur les **entités nommées**, consultez le site https://spacy.io/usage/linguistic-features#named-entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunks de noms\n",
    "Similaire à `Doc.ents`, `Doc.noun_chunks` est une autre propriété d'objet. *Les \"noun chunks\" sont des \"phrases de base\" - des phrases plates qui ont un nom comme tête. Par exemple, dans la [chanson de Sheb Wooley de 1958] (https://en.wikipedia.org/wiki/The_Purple_People_Eater), un *\"mangeur d'hommes borgne, unicorne, volant et violet \"* serait un long morceau de nom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars\n",
      "insurance liability\n",
      "manufacturers\n"
     ]
    }
   ],
   "source": [
    "doc9 = nlp(u\"Autonomous cars shift insurance liability toward manufacturers.\")\n",
    "\n",
    "for chunk in doc9.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red cars\n",
      "higher insurance rates\n"
     ]
    }
   ],
   "source": [
    "doc10 = nlp(u\"Red cars do not carry higher insurance rates.\")\n",
    "\n",
    "for chunk in doc10.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He\n",
      "a one-eyed, one-horned, flying, purple people-eater\n"
     ]
    }
   ],
   "source": [
    "doc11 = nlp(u\"He was a one-eyed, one-horned, flying, purple people-eater.\")\n",
    "\n",
    "for chunk in doc11.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous examinerons d'autres composants de noun_chunks en plus de `.text` dans une prochaine section.<br>Pour plus d'informations sur **noun_chunks** visitez https://spacy.io/usage/linguistic-features#noun-chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Visualiseurs intégrés\n",
    "\n",
    "spaCy inclut un outil de visualisation intégré appelé **displaCy**. displaCy est capable de détecter si vous travaillez dans un notebook Jupyter, et retournera des balises qui peuvent être rendues dans une cellule immédiatement. Lorsque vous exportez votre notebook, les visualisations seront incluses en HTML.\n",
    "\n",
    "Pour plus d'informations, visitez le site https://spacy.io/usage/visualizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation de l'analyse des dépendances\n",
    "Exécutez la cellule ci-dessous pour importer displacy et afficher le graphique de dépendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"f5e40eb709b74bd68a2cac37ebf27ed5-0\" class=\"displacy\" width=\"1370\" height=\"357.0\" direction=\"ltr\" style=\"max-width: none; height: 357.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">going</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">build</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">factory</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">6</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1260\">million.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1260\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-0\" stroke-width=\"2px\" d=\"M70,222.0 C70,112.0 260.0,112.0 260.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,224.0 L62,212.0 78,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-1\" stroke-width=\"2px\" d=\"M180,222.0 C180,167.0 255.0,167.0 255.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M180,224.0 L172,212.0 188,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-2\" stroke-width=\"2px\" d=\"M400,222.0 C400,167.0 475.0,167.0 475.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400,224.0 L392,212.0 408,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-3\" stroke-width=\"2px\" d=\"M290,222.0 C290,112.0 480.0,112.0 480.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M480.0,224.0 L488.0,212.0 472.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-4\" stroke-width=\"2px\" d=\"M620,222.0 C620,112.0 810.0,112.0 810.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M620,224.0 L612,212.0 628,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-5\" stroke-width=\"2px\" d=\"M730,222.0 C730,167.0 805.0,167.0 805.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M730,224.0 L722,212.0 738,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-6\" stroke-width=\"2px\" d=\"M510,222.0 C510,57.0 815.0,57.0 815.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M815.0,224.0 L823.0,212.0 807.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-7\" stroke-width=\"2px\" d=\"M510,222.0 C510,2.0 930.0,2.0 930.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M930.0,224.0 L938.0,212.0 922.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-8\" stroke-width=\"2px\" d=\"M1060,222.0 C1060,112.0 1250.0,112.0 1250.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1060,224.0 L1052,212.0 1068,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-9\" stroke-width=\"2px\" d=\"M1170,222.0 C1170,167.0 1245.0,167.0 1245.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1170,224.0 L1162,212.0 1178,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-10\" stroke-width=\"2px\" d=\"M950,222.0 C950,57.0 1255.0,57.0 1255.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f5e40eb709b74bd68a2cac37ebf27ed5-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1255.0,224.0 L1263.0,212.0 1247.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(u'Apple is going to build a U.K. factory for $6 million.')\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 110})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'argument optionnel `'distance'` définit la distance entre les mots. Si la distance est trop faible, le texte qui apparaît sous les flèches courtes peut être trop compressé pour être lu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation de l'outil de reconnaissance des entités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nearly 20 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    iPods\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(u'Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million.')\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Créer des visualisations en dehors de Jupyter\n",
    "Si vous utilisez un autre IDE Python ou si vous écrivez un script, vous pouvez choisir de faire en sorte que spaCy serve le html séparément :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guill\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\spacy\\displacy\\__init__.py:106: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"7a56c099de054c1f948afdea3cd11ced-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">sentence.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7a56c099de054c1f948afdea3cd11ced-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7a56c099de054c1f948afdea3cd11ced-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7a56c099de054c1f948afdea3cd11ced-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7a56c099de054c1f948afdea3cd11ced-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7a56c099de054c1f948afdea3cd11ced-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7a56c099de054c1f948afdea3cd11ced-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Jan/2024 11:05:25] \"GET / HTTP/1.1\" 200 3395\n",
      "127.0.0.1 - - [18/Jan/2024 11:05:26] \"GET /favicon.ico HTTP/1.1\" 200 3395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'This is a sentence.')\n",
    "displacy.serve(doc, style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Après avoir exécuté la cellule ci-dessus, cliquez sur le lien ci-dessous pour voir l'analyse de la dépendance** :</font>\n",
    "\n",
    "http://127.0.0.1:5000\n",
    "<br><br>\n",
    "<font color=red>**Pour arrêter le serveur et revenir à jupyter**, interrompez le noyau soit par le menu **Kernel** ci-dessus, soit en frappant le carré noir sur la barre d'outils, soit en tapant le raccourci clavier `Esc`, `I`, `I`</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est très bien ! Vous devriez maintenant comprendre comment la tokenisation divise le texte en éléments individuels, comment les entités nommées fournissent un contexte et comment certains outils aident à visualiser les règles de grammaire et les étiquettes d'entités.\n",
    "## À suivre : Stemming"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
