{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, naive_bayes, ensemble, tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquak may allah forgiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near rong sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resid ask place notifi offic evacu shelter pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>peopl receiv wildfir evacu order california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo rubi alaska smoke wildfir pour ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                     processed_text  \n",
       "0       1             deed reason earthquak may allah forgiv  \n",
       "1       1                  forest fire near rong sask canada  \n",
       "2       1  resid ask place notifi offic evacu shelter pla...  \n",
       "3       1        peopl receiv wildfir evacu order california  \n",
       "4       1  got sent photo rubi alaska smoke wildfir pour ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_processed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7613"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On drop ensuite les colonnes inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id','keyword', 'location'], axis = 1, inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde ensuite les valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text              0\n",
       "target            0\n",
       "processed_text    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text              0\n",
       "target            0\n",
       "processed_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 blanks:  []\n"
     ]
    }
   ],
   "source": [
    "blanks = []  # start with an empty list\n",
    "\n",
    "for i,lb,rv,pv in df.itertuples():  # iterate over the DataFrame\n",
    "    if type(rv)==str:            # avoid NaN values\n",
    "        if rv.isspace():         # test 'review' for whitespace\n",
    "            blanks.append(i)     # add matching index numbers to the list\n",
    "\n",
    "print(len(blanks), 'blanks: ', blanks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque qu'aucune donnée n'est manquante et pas d'espaces marquants manquants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7609"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vu que les données sont déjà bien préparées, on peut passer directement à la modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division du dataset (target/feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the features and the target\n",
    "features = 'processed_text'\n",
    "target = 'target'\n",
    "\n",
    "# create the X and y\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAG OF WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence sans cross-validation ni hyperparameters tuning avec bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline\n",
    "text_clf = Pipeline([('bag', CountVectorizer()), ('clf', tree.DecisionTreeClassifier())])\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[705 159]\n",
      " [245 413]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78       864\n",
      "           1       0.72      0.63      0.67       658\n",
      "\n",
      "    accuracy                           0.73      1522\n",
      "   macro avg       0.73      0.72      0.72      1522\n",
      "weighted avg       0.73      0.73      0.73      1522\n",
      "\n",
      "0.7345597897503285\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# Print the overall accuracy\n",
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline for the other models\n",
    "text_clf = Pipeline([('bag', CountVectorizer()), ('clf', svm.LinearSVC())])\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[715 149]\n",
      " [205 453]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.80       864\n",
      "           1       0.75      0.69      0.72       658\n",
      "\n",
      "    accuracy                           0.77      1522\n",
      "   macro avg       0.76      0.76      0.76      1522\n",
      "weighted avg       0.77      0.77      0.77      1522\n",
      "\n",
      "0.7674113009198423\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# Print the overall accuracy\n",
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline for the other models\n",
    "text_clf = Pipeline([('bag', CountVectorizer()), ('clf', naive_bayes.MultinomialNB())])\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[733 131]\n",
      " [182 476]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82       864\n",
      "           1       0.78      0.72      0.75       658\n",
      "\n",
      "    accuracy                           0.79      1522\n",
      "   macro avg       0.79      0.79      0.79      1522\n",
      "weighted avg       0.79      0.79      0.79      1522\n",
      "\n",
      "0.7943495400788436\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# Print the overall accuracy\n",
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline for the other models\n",
    "text_clf = Pipeline([('bag', CountVectorizer()), ('clf', ensemble.RandomForestClassifier())])\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[778  86]\n",
      " [247 411]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.82       864\n",
      "           1       0.83      0.62      0.71       658\n",
      "\n",
      "    accuracy                           0.78      1522\n",
      "   macro avg       0.79      0.76      0.77      1522\n",
      "weighted avg       0.79      0.78      0.78      1522\n",
      "\n",
      "0.7812089356110381\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# Print the overall accuracy\n",
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir :\n",
    "\n",
    "- LinearSVC il y a une accuracy de 0.767\n",
    "- DecisionTreeClassifier il y a une accuracy de 0.720\n",
    "- MultinomialNB il y a une accuracy de 0.794\n",
    "- RandomForestClassifier il y a une accuracy de 0.787\n",
    "\n",
    "On peut voir qu'avec bag of words le plus performant sans cross-validation et hyperparameters tunning est le MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant on va essayer avec le tuning des hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7974368315314113\n",
      "{'clf__alpha': 1.1, 'clf__fit_prior': True}\n",
      "Pipeline(steps=[('vect', CountVectorizer()), ('clf', MultinomialNB(alpha=1.1))])\n",
      "0.7943495400788436\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', naive_bayes.MultinomialNB()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "  'clf__alpha': np.linspace(0.5, 1.5, 6),\n",
    "  'clf__fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "\n",
    "print(gs_clf.best_score_)\n",
    "print(gs_clf.best_params_)\n",
    "print(gs_clf.best_estimator_)\n",
    "print(gs_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7966147340697536\n",
      "{'clf__C': 0.1, 'clf__loss': 'hinge'}\n",
      "Pipeline(steps=[('vect', CountVectorizer()),\n",
      "                ('clf', LinearSVC(C=0.1, loss='hinge'))])\n",
      "0.7950065703022339\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', svm.LinearSVC()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__C': np.linspace(0.1, 1, 10),\n",
    "    'clf__loss': ['hinge', 'squared_hinge']\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "\n",
    "print(gs_clf.best_score_)\n",
    "print(gs_clf.best_params_)\n",
    "print(gs_clf.best_estimator_)\n",
    "print(gs_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7698368622942902\n",
      "{'clf__max_depth': 50, 'clf__n_estimators': 100}\n",
      "Pipeline(steps=[('vect', CountVectorizer()),\n",
      "                ('clf', RandomForestClassifier(max_depth=50))])\n",
      "0.7674113009198423\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', ensemble.RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__n_estimators': [50, 100, 200],\n",
    "    'clf__max_depth': [10, 20, 30, 40, 50]\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "\n",
    "print(gs_clf.best_score_)\n",
    "print(gs_clf.best_params_)\n",
    "print(gs_clf.best_estimator_)\n",
    "print(gs_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7453618888407656\n",
      "{'clf__max_depth': 50}\n",
      "Pipeline(steps=[('vect', CountVectorizer()),\n",
      "                ('clf', DecisionTreeClassifier(max_depth=50))])\n",
      "0.7365308804204993\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', tree.DecisionTreeClassifier()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__max_depth': [10, 20, 30, 40, 50]\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "\n",
    "print(gs_clf.best_score_)\n",
    "print(gs_clf.best_params_)\n",
    "print(gs_clf.best_estimator_)\n",
    "print(gs_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir :\n",
    "\n",
    "- LinearSVC il y a une accuracy de 0.796\n",
    "- DecisionTreeClassifier il y a une accuracy de 0.745\n",
    "- MultinomialNB il y a une accuracy de 0.797\n",
    "- RandomForestClassifier il y a une accuracy de 0.769\n",
    "\n",
    "On peut voir qu'avec bag of words le plus performant sans cross-validation et hyperparameters tunning est le MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant on va essayer de faire sans cross-validation et hyperparameters tunning avec TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()), ('clf', tree.DecisionTreeClassifier())])\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[683 181]\n",
      " [234 424]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.77       864\n",
      "           1       0.70      0.64      0.67       658\n",
      "\n",
      "    accuracy                           0.73      1522\n",
      "   macro avg       0.72      0.72      0.72      1522\n",
      "weighted avg       0.73      0.73      0.73      1522\n",
      "\n",
      "0.7273324572930355\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# Print the overall accuracy\n",
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline for the other models\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()), ('clf', svm.LinearSVC())])\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[726 138]\n",
      " [202 456]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81       864\n",
      "           1       0.77      0.69      0.73       658\n",
      "\n",
      "    accuracy                           0.78      1522\n",
      "   macro avg       0.78      0.77      0.77      1522\n",
      "weighted avg       0.78      0.78      0.77      1522\n",
      "\n",
      "0.7766097240473062\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# Print the overall accuracy\n",
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline for the other models\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()), ('clf', naive_bayes.MultinomialNB())])\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[769  95]\n",
      " [213 445]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83       864\n",
      "           1       0.82      0.68      0.74       658\n",
      "\n",
      "    accuracy                           0.80      1522\n",
      "   macro avg       0.80      0.78      0.79      1522\n",
      "weighted avg       0.80      0.80      0.79      1522\n",
      "\n",
      "0.797634691195795\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# Print the overall accuracy\n",
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline for the other models\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()), ('clf', ensemble.RandomForestClassifier())])\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[767  97]\n",
      " [233 425]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.82       864\n",
      "           1       0.81      0.65      0.72       658\n",
      "\n",
      "    accuracy                           0.78      1522\n",
      "   macro avg       0.79      0.77      0.77      1522\n",
      "weighted avg       0.79      0.78      0.78      1522\n",
      "\n",
      "0.783180026281209\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# Print the overall accuracy\n",
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir :\n",
    "\n",
    "- LinearSVC il y a une accuracy de 0.776\n",
    "- DecisionTreeClassifier il y a une accuracy de 0.727\n",
    "- MultinomialNB il y a une accuracy de 0.797\n",
    "- RandomForestClassifier il y a une accuracy de 0.783\n",
    "\n",
    "On peut voir qu'avec TF-IDF le plus performant sans cross-validation et hyperparameters tunning est le MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant on va essayer avec le tuning des hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7997373012050144\n",
      "{'clf__alpha': 0.7, 'clf__fit_prior': True}\n",
      "Pipeline(steps=[('vect', TfidfVectorizer()), ('clf', MultinomialNB(alpha=0.7))])\n",
      "0.7996057818659659\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', naive_bayes.MultinomialNB()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__alpha': np.linspace(0.5, 1.5, 6),\n",
    "    'clf__fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "\n",
    "print(gs_clf.best_score_)\n",
    "print(gs_clf.best_params_)\n",
    "print(gs_clf.best_estimator_)\n",
    "print(gs_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8002291024930075\n",
      "{'clf__C': 0.2, 'clf__loss': 'squared_hinge'}\n",
      "Pipeline(steps=[('vect', TfidfVectorizer()), ('clf', LinearSVC(C=0.2))])\n",
      "0.7956636005256241\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', svm.LinearSVC()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__C': np.linspace(0.1, 1, 10),\n",
    "    'clf__loss': ['hinge', 'squared_hinge']\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "\n",
    "print(gs_clf.best_score_)\n",
    "print(gs_clf.best_params_)\n",
    "print(gs_clf.best_estimator_)\n",
    "print(gs_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7708222188940745\n",
      "{'clf__max_depth': 50, 'clf__n_estimators': 200}\n",
      "Pipeline(steps=[('vect', TfidfVectorizer()),\n",
      "                ('clf',\n",
      "                 RandomForestClassifier(max_depth=50, n_estimators=200))])\n",
      "0.7588699080157687\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', ensemble.RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__n_estimators': [50, 100, 200],\n",
    "    'clf__max_depth': [10, 20, 30, 40, 50]\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "\n",
    "print(gs_clf.best_score_)\n",
    "print(gs_clf.best_params_)\n",
    "print(gs_clf.best_estimator_)\n",
    "print(gs_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7341897017215069\n",
      "{'clf__max_depth': 50}\n",
      "Pipeline(steps=[('vect', TfidfVectorizer()),\n",
      "                ('clf', DecisionTreeClassifier(max_depth=50))])\n",
      "0.7352168199737188\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', tree.DecisionTreeClassifier()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__max_depth': [10, 20, 30, 40, 50]\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "\n",
    "print(gs_clf.best_score_)\n",
    "print(gs_clf.best_params_)\n",
    "print(gs_clf.best_estimator_)\n",
    "print(gs_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir :\n",
    "\n",
    "- LinearSVC il y a une accuracy de 0.800\n",
    "- DecisionTreeClassifier il y a une accuracy de 0.734\n",
    "- MultinomialNB il y a une accuracy de 0.799\n",
    "- RandomForestClassifier il y a une accuracy de 0.770\n",
    "\n",
    "On peut voir qu'avec TF-IDF le plus performant sans cross-validation et hyperparameters tunning est le LinearSVC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
